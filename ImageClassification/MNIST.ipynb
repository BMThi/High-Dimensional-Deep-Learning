{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image classification on [MNIST](https://yann.lecun.com/exdb/mnist/) dataset\n",
    "\n",
    "_Handling Convolutional Neural Networks_\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial you will learn to : \n",
    "* Write multilayer perceptron and convolutional network with [`Keras`](https://keras.io/) and [`Tensorflow`](https://www.tensorflow.org/)\n",
    "* Understand how `convolutional`, `max pooling`, `stride` and `padding` layers work.\n",
    "* Use these models for image classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.utils as ku\n",
    "import tensorflow.keras.models as km\n",
    "import tensorflow.keras.layers as kl\n",
    "import tensorflow.keras.optimizers as ko\n",
    "import tensorflow.keras.preprocessing.image as k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code lines allow you to check if your computer is using CPU or GPU ressources. <br>\n",
    "**Warning** : You won't be able to use GPU if another notebook is open and still uses GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset that will be used in this TP is the [MNIST DataBase](http://yann.lecun.com/exdb/mnist/).<br>\n",
    "It is composed of 70.000 images (60.000 for learning, 10.000 for test) of 28x28 pixels of handwritten digits from 0 to 9.<br>\n",
    "\n",
    "These data are directly available on the `Keras` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color:purple\">**Todo:** Check that the images are the correct size, as well as the test and train sets.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO BE COMPLETED ###\n",
    "\n",
    "N_x_pixels = ...\n",
    "N_y_pixels = ...\n",
    "N_train = ...\n",
    "N_test = ...\n",
    "N_classes = ...\n",
    "\n",
    "print(\"Train data: %d images  (%d x %d pixels)\" %(N_train, N_x_pixels, N_y_pixels))\n",
    "print(\"Test data: %d images  (%d x %d pixels)\" %(N_test, N_x_pixels, N_y_pixels))\n",
    "print(\"Number of classes: %d classes\" %N_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/MNIST/size.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color:purple\">**Question:**  Is the dataset balanced?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO BE COMPLETED ###\n",
    "\n",
    "[...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/MNIST/histograms.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as rd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color:purple\">**Todo:** View an example of each digit</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO BE COMPLETED ###\n",
    "\n",
    "[...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/MNIST/imshow.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image classification with Multi Layer Perceptron model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first try to learn an image classifier with a MLP model with the following architecture.\n",
    "\n",
    "* A Dense layer with 128 neurons and *relu* activation function\n",
    "* A Dropout Layer with 20% drop rate\n",
    "* A Dense layer with 128 neurons and *relu* activation function\n",
    "* A Dropout Layer with 20% drop rate\n",
    "* A Dense layer with 10 neurons (Number of classes ) and *softmax* activation function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data format\n",
    "\n",
    "Some modifications are required on the data to use them with our model. \n",
    "\n",
    "The first layer is a Dense Layer, which handles 1D vectors as an input. We must first reshape the 2D $28\\times28$ images as a 1D $28\\times28=784$ vector. \n",
    "<!-- We take this opportunity to renormalize the image, _i.e._ divide all its values by $255$ (grayscale image). -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_flatten = x_train.reshape((N_train, N_x_pixels*N_y_pixels))\n",
    "x_test_flatten = x_test.reshape((N_test, N_x_pixels*N_y_pixels))\n",
    "N_dim_flatten = x_train_flatten.shape[1]\n",
    "\n",
    "print(\"Dimensions of flatten train images: %d x %d\" %(x_train_flatten.shape))\n",
    "print(\"Dimensions of flatten test images: %d x %d\" %(x_test_flatten.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color:purple\">**Todo:** Complete the code below to define the previously described network.</span>\n",
    "\n",
    "The `Keras` $\\texttt{Sequential}$ method builds neural networks by juxtaposing layers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO BE COMPLETED ###\n",
    "\n",
    "# Network definition\n",
    "mlp = Sequential()\n",
    "mlp.add( Input(shape=(N_dim_flatten,)) )\n",
    "mlp.add( Dense(128, activation='relu') )\n",
    "mlp.add( Dropout(0.2) )\n",
    "\n",
    "[...]\n",
    "\n",
    "# Summary\n",
    "mlp.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/MNIST/mlp.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above summary displays the number of pararameters/weigths of the model.\n",
    "\n",
    "##### <span style=\"color:purple\">**Todo:** Retrieve these values with the formulas seen in the course.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now instantiate your model by defining :\n",
    "* An _optimizer_: $\\texttt{RMSprop}$\n",
    "* A _loss_ function: $\\texttt{Categorical crossentropy}$\n",
    "* A _metric_: This argument is an option, it allows to compute the metric if you want to check the evolution of the training. Here we choose to compute the accuracy during the training.\n",
    "<br><br>\n",
    "\n",
    "> **Remark**: In Keras you can choose either $\\texttt{sparse\\_categorical\\_crossentropy}$ or $\\texttt{categorical\\_crossentropy}$ loss.\n",
    "> * The former handles 1D ($N\\times1$) vectors where each entry contains the label of the data, _i.e_ $[0,3,5,9,3,4,\\ldots]$.\n",
    "> * The latter handles only one-hot encoding of this vector, ie  2D vectors ($N\\times N_{classes}$) matrices.\n",
    ">  \n",
    "> Keras has a $\\texttt{to\\_categorical}$ function which allows to convert a vector to its one-hot encoding representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.compile(loss = 'sparse_categorical_crossentropy',\n",
    "            optimizer = RMSprop(),\n",
    "            metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Remark**: if you want to restart network training, _you need to reset its weights._\n",
    "\n",
    "To do this, you need to re-execute the previous cells from the network definition! \n",
    "Otherwise, you risk restarting your optimization procedure from a previous run (which may or may not have gone well) and misinterpreting your new results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "epochs = 10\n",
    "\n",
    "t_train_mlp = time.time()\n",
    "history = mlp.fit(x_train_flatten, y_train,\n",
    "                  batch_size = batch_size,\n",
    "                  epochs = epochs,\n",
    "                  verbose = 1,\n",
    "                  validation_data = (x_test_flatten, y_test))\n",
    "t_train_mlp = t_train_mlp - time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color:purple\">**Todo:** Evaluate the performance of this training.</span>\n",
    "\n",
    "You can visualize a confusion matrix between the predictions for $y$ and the true values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO BE COMPLETED ###\n",
    "\n",
    "score_mlp = mlp.evaluate(x_test_flatten, y_test, verbose=0)\n",
    "predict_mlp = mlp.predict(x_test_flatten)\n",
    "\n",
    "print('Test loss:', ...)\n",
    "print('Test accuracy:', ...)\n",
    "print(\"Running time: %.2f seconds\" %t_train_mlp)\n",
    "\n",
    "[...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/MNIST/mlp_results.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color:purple\">**Question:** What can you say about these results?</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color:purple\">**Exercise:** Normalize the data in order to have values between 0 and 1 and run again the learning.</span>\n",
    "\n",
    "What can you say about these results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO BE COMPLETED ###\n",
    "\n",
    "[...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/MNIST/mlp_norm.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Layers\n",
    "\n",
    "In this part we will use convolution layers to build a convolutional classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data format\n",
    "\n",
    "The convolution architecture takes as input images and not 1D vectors. However, some data formating are still required.\n",
    "\n",
    "A third dimension is required : the $\\texttt{channels}$ dimension which will allow to describe each pixel. In our case this dimension's size is only 1 because the images are only defined with grey scale. However for colour images, each pixel is coded with several values (Images are generally encoded with 3 values (RGB channels)). \n",
    "\n",
    "Hence, we need to reshape the images from a $28\\times28$ dimension to a $28\\times28\\times1$ dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_conv = np.expand_dims(x_train, axis=-1)\n",
    "x_test_conv = np.expand_dims(x_test, axis=-1)\n",
    "\n",
    "print(\"Train data: %d images\" %x_train_conv.shape[0], x_train_conv.shape[1:])\n",
    "print(\"Test data: %d images\" %x_test_conv.shape[0], x_test_conv.shape[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "### Edge detection\n",
    "\n",
    "We will first check the transformation applied by a convolution layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We select an example for each of the digits ($0$ to $9$), and define a new test image (a $+$) so that we can observe the effect of the convolution filters.\n",
    "Try testing the proposed filters (or even others!) on different images, digit or plus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(11, 5))\n",
    "\n",
    "# Plus image test\n",
    "img_plus = np.zeros((28,28), dtype=int)\n",
    "img_plus[4:24,11:17] = 1\n",
    "img_plus[11:17,4:24] = 1\n",
    "img_plus = np.expand_dims(img_plus, axis=-1)\n",
    "\n",
    "ax = fig.add_subplot(1, 11, 11)\n",
    "ax.imshow(img_plus[:,:,0], cmap=plt.cm.gray_r)\n",
    "ax.grid(False)\n",
    "ax.axis('off')\n",
    "\n",
    "\n",
    "# Digits\n",
    "sample_index = np.zeros(10, dtype=int)\n",
    "for i in range(10):\n",
    "    sample_index[i] = np.where(y_train==i)[0][0]\n",
    "    ax = fig.add_subplot(1, 11, i+1)\n",
    "    ax.imshow(x_train[sample_index[i]], cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    ax.grid(False)\n",
    "    ax.axis('off')\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some examples of $3\\times3$ convolution filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_filter_1 = np.array([\n",
    "        [0.2, -0.2, 0],\n",
    "        [0.2, -0.2, 0],\n",
    "        [0.2, -0.2, 0],\n",
    "    ])\n",
    "\n",
    "conv_filter_2 = 1/9 * np.array([\n",
    "        [1, 1, 1],\n",
    "        [1, 1, 1],\n",
    "        [1, 1, 1],\n",
    "    ])\n",
    "\n",
    "conv_filter_3 = np.array([\n",
    "        [0, -1, 0],\n",
    "        [-1, 5, -1],\n",
    "        [0, -1, 0],\n",
    "    ])\n",
    "\n",
    "conv_filter_4 = np.array([\n",
    "        [-1, 2, -1],\n",
    "        [-1, 2, -1],\n",
    "        [-1, 2, -1],\n",
    "    ])\n",
    "\n",
    "conv_filter_5 = np.array([\n",
    "        [-1, -1, 2],\n",
    "        [-1, 2, -1],\n",
    "        [2, -1, -1],\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following code, we define a convolutional network with  only one filter for which we manually define the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_filter = conv_filter_1\n",
    "\n",
    "def my_init_filter(shape, conv_filter=conv_filter, dtype=None, partition_info=None):\n",
    "    xf,yf = conv_filter.shape\n",
    "    array = conv_filter.reshape(xf, yf, 1, 1)\n",
    "    return array\n",
    "print(my_init_filter(0, conv_filter_2).shape)\n",
    "\n",
    "conv_layer = Sequential()\n",
    "conv_layer.add( Input(shape=(28, 28, 1)) )\n",
    "conv_layer.add( Conv2D(kernel_size=(3,3), filters=1, kernel_initializer=my_init_filter) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in  $\\texttt{my\\_init\\_filter}$ two dimensions have been added to the conv filter.\n",
    "\n",
    "##### <span style=\"color:purple\">**Question:** What do these dimensions represent?</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The following codes allow to display the image, the filter and the convoluted image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_conv_layer(conv_filter):    \n",
    "    def my_init_filter(shape, conv_filter=conv_filter, dtype=None, partition_info=None):\n",
    "        xf,yf = conv_filter.shape\n",
    "        array = conv_filter.reshape(xf, yf, 1, 1)\n",
    "        return array\n",
    "    \n",
    "    conv_layer = Sequential()\n",
    "    conv_layer.add( Input(shape=(28, 28, 1)) )\n",
    "    conv_layer.add( Conv2D(kernel_size=(3,3), filters=1, kernel_initializer=my_init_filter) )\n",
    "    return conv_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHOICES\n",
    "\n",
    "# Image choice : Digit or Plus\n",
    "idx = sample_index[9] #####\n",
    "x = x_train_conv[idx] #####\n",
    "# x = img_plus #####\n",
    "\n",
    "# Filter choice\n",
    "conv_filter = conv_filter_3 #####\n",
    "conv_layer = build_conv_layer(conv_filter)\n",
    "\n",
    "# --- #\n",
    "\n",
    "img_in = np.expand_dims(x, 0)\n",
    "img_out = conv_layer.predict(img_in)\n",
    "\n",
    "# Original image\n",
    "fig, (ax0, ax1, ax2) = plt.subplots(ncols=3, figsize=(15, 5))\n",
    "ax0.imshow(img_in[0,:,:,0], cmap=plt.cm.gray_r)\n",
    "ax0.set_title(\"Original image\")\n",
    "ax0.grid(False)\n",
    "\n",
    "# Filter\n",
    "norm_conv_filter = (conv_filter-conv_filter.min())/conv_filter.max()\n",
    "ax1.imshow(norm_conv_filter.astype(np.uint8), cmap=plt.cm.gray_r)   # \"binary\"\n",
    "ax1.set_title(\"Filter\")\n",
    "ax1.grid(False)\n",
    "\n",
    "# Filtered image\n",
    "ax2.imshow(img_out[0,:,:,0].astype(np.uint8), cmap=plt.cm.gray_r)\n",
    "ax2.set_title(\"Filtered image\")\n",
    "ax2.grid(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color:purple\">**Question:** What do you see?</span>\n",
    "\n",
    "* Are the output image coherent according to the designed filter ?\n",
    "* How do the proposed filters affect the image?\n",
    "* Change the code in order to test different filters (to detect horizontal edges, etc...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strides and Padding\n",
    "\n",
    "We will now study the effect on $\\texttt{strides}$ and $\\texttt{padding}$ arguments on the image.\n",
    "\n",
    "$\\texttt{padding}$ can take the values $\\texttt{\"same\"}$ or $\\texttt{\"valid\"}$. $\\texttt{\"valid\"}$ means no padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_conv_layer_sp(conv_filter, strides=2, padding=\"same\"):    \n",
    "    def my_init_filter(shape, conv_filter=conv_filter, dtype=None, partition_info=None):\n",
    "        xf,yf = conv_filter.shape\n",
    "        array = conv_filter.reshape(xf, yf, 1, 1)\n",
    "        return array\n",
    "    \n",
    "    conv_layer = Sequential()\n",
    "    conv_layer.add( Input(shape=(28, 28, 1)) )\n",
    "    conv_layer.add( Conv2D(kernel_size=(5,5), filters=1, kernel_initializer=my_init_filter,\n",
    "                  strides=strides, padding=padding) )  ### NEW\n",
    "    return conv_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHOICES\n",
    "\n",
    "# Image choice : Digit or Plus\n",
    "idx = sample_index[9] #####\n",
    "x = x_train_conv[idx] #####\n",
    "# x = img_plus #####\n",
    "\n",
    "# Filter choice\n",
    "conv_filter = conv_filter_3 #####\n",
    "conv_layer = build_conv_layer_sp(conv_filter, padding=\"valid\")\n",
    "\n",
    "# --- #\n",
    "\n",
    "img_in = np.expand_dims(x, 0)\n",
    "img_out = conv_layer.predict(img_in)\n",
    "\n",
    "fig, (ax0, ax1, ax2) = plt.subplots(ncols=3, figsize=(15, 5))\n",
    "ax0.imshow(img_in[0,:,:,0].astype(np.uint8), cmap=plt.cm.gray_r);\n",
    "ax0.set_title(\"Original image\")\n",
    "ax0.grid(False)\n",
    "\n",
    "norm_conv_filter = (conv_filter-conv_filter.min())/conv_filter.max()\n",
    "ax1.imshow(norm_conv_filter.astype(np.uint8), cmap=plt.cm.gray_r);\n",
    "ax1.set_title(\"Filter\")\n",
    "ax1.grid(False)\n",
    "\n",
    "ax2.imshow(img_out[0,:,:,0].astype(np.uint8), cmap=plt.cm.gray_r);\n",
    "ax2.set_title(\"Filtered image\")\n",
    "ax2.grid(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color:purple\">**Question:** What do you see?</span>\n",
    "\n",
    "* Check the dimension of the output images. Are they coherent? <br>\n",
    "* Change both *strides* and *padding* arguments and understand the effect of these changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import MaxPool2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color:purple\">**Exercise:** Write a similar code than above to check and understand the behaviour of the $\\texttt{max pooling}$ layer.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO BE COMPLETED ###\n",
    "\n",
    "[...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/MNIST/max_pooling.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color:purple\">**Question:** What are the dimension of the output image?</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network (CNN or ConvNet)\n",
    "\n",
    "We will now build convolutional networks and see the performances on this kind of model on  image classification problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LeNet5\n",
    "\n",
    "We first test the  [LeNet5](https://en.wikipedia.org/wiki/LeNet) model, proposed by _LeCun et al._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.optimizers import Adadelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LeNet = Sequential()\n",
    "LeNet.add(Input(shape=(28,28,1)))\n",
    "\n",
    "LeNet.add(Conv2D(filters = 6, kernel_size = 5, strides = 1, activation = 'tanh'))\n",
    "LeNet.add(MaxPool2D(pool_size = 2, strides = 2))\n",
    "\n",
    "LeNet.add(Conv2D(filters = 16, kernel_size = 5,strides = 1, activation = 'tanh'))\n",
    "LeNet.add(MaxPool2D(pool_size = 2, strides = 2))\n",
    "\n",
    "LeNet.add(Flatten())\n",
    "LeNet.add(Dense(units = 120, activation = 'tanh'))\n",
    "LeNet.add(Dense(units = 84, activation = 'tanh'))\n",
    "LeNet.add(Dense(units = 10, activation = 'softmax'))\n",
    "\n",
    "LeNet.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color:purple\">**Exercise:** Retrieve 'manually' the number of parameters of this model.</span>\n",
    "\n",
    "What can you say about the total number of parameters compared with the MLP model defined before? Which layer has the highest number of parameters?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=128\n",
    "epochs=10\n",
    "\n",
    "LeNet.compile(loss = \"sparse_categorical_crossentropy\",\n",
    "              optimizer = Adadelta(),\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "t_train_LeNet = time.time()\n",
    "LeNet.fit(x_train_conv, y_train,\n",
    "          batch_size = batch_size,\n",
    "          epochs = epochs,\n",
    "          verbose = 1,\n",
    "          validation_data = (x_test_conv, y_test))\n",
    "t_train_LeNet = time.time() - t_train_LeNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color:purple\">**Question:** Why is the training time longer?</span>\n",
    "\n",
    "##### <span style=\"color:purple\">**Exercise:** Compare the accuracy with the one obtained with the optimizer $\\texttt{Adam}$. </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_LeNet = LeNet.evaluate(x_test_conv, y_test, verbose=0)\n",
    "predict_LeNet = LeNet.predict(x_test_conv)\n",
    "\n",
    "print('Test loss:', score_LeNet[0])\n",
    "print('Test accuracy:', score_LeNet[1])\n",
    "print(\"Time Running: %.2f seconds\" %t_train_LeNet )\n",
    "\n",
    "fig = plt.figure(figsize=(7,6))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax = sns.heatmap(pd.DataFrame(confusion_matrix(y_test, predict_LeNet.argmax(1))), annot=True, fmt=\"d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A more complex architecture\n",
    "\n",
    "\n",
    "We will now design a more complex architecture to try to improve the results of the classification :\n",
    "\n",
    "* A $\\texttt{Conv2D}$ layer with $32 - 3\\times3$ filters and the $\\texttt{Relu}$ activation function,\n",
    "* A $\\texttt{Conv2D}$ layer with $64 - 3\\times3$ filters and the $\\texttt{Relu}$ activation function,\n",
    "* A $\\texttt{MaxPooling}$ layer with a $2\\times2$ window,\n",
    "* A $\\texttt{Dropout}$ layer with a $25%$ drop rate,\n",
    "* A $\\texttt{Flatten}$ layer,\n",
    "* A $\\texttt{Dense}$ layer with $128$ neurons  and the $\\texttt{Relu}$ activation function,\n",
    "* A $\\texttt{Dropout}$ layer with a $50\\%$ drop rate,\n",
    "* A $\\texttt{Dense}$ layer with $10$ neurons  and the $\\texttt{softmax}$ activation function.\n",
    "\n",
    "\n",
    "##### <span style=\"color:purple\">**Exercise:** Define this model and train it.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO BE COMPLETED ###\n",
    "\n",
    "[...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %load solutions/MNIST/cnn.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color:purple\">**Exercise:** Compare the accuracy with the one obtained with the optimizer Adam.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO BE COMPLETED ###\n",
    "\n",
    "[...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/MNIST/cnn_results.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color:purple\">**Exercise:** Comment the results.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
