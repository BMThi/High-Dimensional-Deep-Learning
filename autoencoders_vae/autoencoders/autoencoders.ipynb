{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Outcomes\n",
    "After doing the exercises below, you will be able to:\n",
    "- Apply AEs to the image compression task.\n",
    "- Define and train simple autoencoder models using pytorch.\n",
    "- Evaluate the impact of different architecture choices.\n",
    "- Visualize loss functions and image reconstructions.\n",
    "- Benchmark results and compare them to common baselines.\n",
    "- Argue about tranferability of latent representations in autoencoders."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The MNIST dataset\n",
    "The MNIST dataset consists of **70,000 grayscale images** of handwritten digits (0 to 9). Each image is a **28x28 pixel** grayscale image. The training set contains 60,000 images while the test set contains 10,000 images. The grayscale values are integers ranging from 0 (black) to 255 (white). However, typicially the data is normalized to range between 0 and 1 for deep learning models.\n",
    "\n",
    "The MNIST dataset can be downloaded from the **torchvision** library, using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MNIST dataset\n",
    "transform = torchvision.transforms.ToTensor()\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root='../../data', train=True, download=True, transform=transform)\n",
    "test_dataset = torchvision.datasets.MNIST(root='../../data', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 9 random images from the MNIST train dataset\n",
    "def plot_images(img_dataset):\n",
    "    \"\"\"Plots 9 random images from the given dataset\n",
    "\n",
    "    Args:\n",
    "        img_dataset (torch.utils.data.Dataset): The dataset to plot images from\n",
    "    \"\"\"\n",
    "    # Set up a 3x3 grid for plotting 9 random images\n",
    "    figure = plt.figure(figsize=(8, 8))\n",
    "    cols, rows = 3, 3\n",
    "    \n",
    "    # Plot 9 random images from the img_dataset\n",
    "    for i in range(1, cols * rows + 1):\n",
    "        random_idx = torch.randint(len(img_dataset), size=(1,)).item()  # Pick a random index\n",
    "        img, label = img_dataset[random_idx]  # Get the image and its label\n",
    "        figure.add_subplot(rows, cols, i)  # Add subplot\n",
    "        plt.title(f'Label: {label}')  # Set title to show the label\n",
    "        plt.axis(\"off\")  # Turn off axis\n",
    "        plt.imshow(img.squeeze(), cmap=\"gray\")  # Plot image\n",
    "    \n",
    "    plt.show()  # Display the figure\n",
    "\n",
    "plot_images(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.** The models that we will be using in this notebook will mainly consist of fully connected layers and activations (no convolutions). Prepare the data for use with such models (complete all the `TODO` flags below):\n",
    "1. Flatten the data.\n",
    "2. Normalize pixel values to the interval $[0, 1]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the images\n",
    "train_dataset = train_dataset.data.view( , ).float() # TODO: Complete with the appropriate dimensions\n",
    "train_dataset = # TODO: Normalize pixel values.\n",
    "\n",
    "# TODO: Repeat the same operations for the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/prepare_data.py\n",
    "# Flatten the images and normalize the pixel values\n",
    "train_dataset = train_dataset.data.view(-1, 28*28).float()\n",
    "train_dataset = train_dataset / 255.0\n",
    "test_dataset = test_dataset.data.view(-1, 28*28).float()\n",
    "test_dataset = test_dataset / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. A couple of examples\n",
    "We begin with a couple of examples that will prove useful in the sequel:\n",
    "1. How to train PCA on MNIST using `scikit-learn`.\n",
    "2. How to train a simple AE on MNIST using `Pytorch`.\n",
    "Don't hesitate to refer back to these examples if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.1. **Example.** training and evaluating PCA\n",
    "In order to train and evaluate a PCA model, we use the PCA class provided by the `scikit-learn` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Instantiate a PCA model with the desired number of principal components\n",
    "pca = PCA(n_components=10)\n",
    "\n",
    "# Fit the PCA model to the training data\n",
    "pca.fit(train_dataset)\n",
    "\n",
    "# Evaluate the PCA model on the training and test data\n",
    "pca_reconstruction_train = pca.inverse_transform(pca.transform(train_dataset))\n",
    "pca_reconstruction_test = pca.inverse_transform(pca.transform(test_dataset))\n",
    "pca_mse_train = mean_squared_error(train_dataset, pca_reconstruction_train)\n",
    "pca_mse_test = mean_squared_error(test_dataset, pca_reconstruction_test)\n",
    "\n",
    "# Print the PCA reconstruction MSE on the training and test data\n",
    "print(f\"PCA Reconstruction MSE on the train set: {pca_mse_train:.6f}\")\n",
    "print(f\"PCA Reconstruction MSE on the test set: {pca_mse_test:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code allows us to plot six random images from the MNIST test dataset along with their reconstructions using the PCA model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_comparison(original_images, reconstructions, n_images=6):\n",
    "    \"\"\"Plots the original images and its reconstructions for comparison\n",
    "\n",
    "    Args:\n",
    "        original_image (torch.Tensor): The original images\n",
    "        reconstructions (torch.Tensor): Reconstruction of the original images\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(2, n_images, figsize=(20, 7))\n",
    "    \n",
    "    for i in range(n_images):\n",
    "        # Plot original images\n",
    "        ax[0, i].imshow(original_images[i], cmap='gray')\n",
    "        ax[0, i].axis('off')\n",
    "        ax[0, 0].set_title('Original')\n",
    "\n",
    "        # Reconstructed images\n",
    "        ax[1, i].imshow(reconstructions[i], cmap='gray')\n",
    "        ax[1, i].axis('off')\n",
    "        ax[1, 0].set_title('Recomstruction')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Select 6 random images from the test dataset\n",
    "random_images = test_dataset[torch.randint(len(test_dataset), size=(6,))]\n",
    "\n",
    "# Get the PCA reconstructions of the selected images\n",
    "pca_reconstruction = pca.inverse_transform(pca.transform(random_images))\n",
    "\n",
    "# Reshape the images for plotting\n",
    "random_images = random_images.reshape(-1, 28, 28)\n",
    "pca_reconstruction = pca_reconstruction.reshape(-1, 28, 28)\n",
    "\n",
    "# Plot the original images and their PCA reconstructions\n",
    "image_comparison(random_images, pca_reconstruction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.2. **Example.** Training and evaluating an AE\n",
    "\n",
    "In order to train and evaluate an AE model, we will use the `pytorch` library. For this example we will train a simple autoencoder with one fully connected layer plus activation in the encoder/decoder, and a free hidden dimension parameter. The steps we follow are:\n",
    "1. We create an `Autoencoder` class with the desired architecture and a free hidden dimension parameter.\n",
    "2. We prepare the data loaders to train the AE model using minibatch gradient descent.\n",
    "3. We instatiate a model of the `Autoencoder` class with the desired hidden dimension parameter.\n",
    "4. We define the loss and optimizer that will be used to train the AE.\n",
    "5. We perform the actual training.\n",
    "6. We evaluate the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I.2.1. Create the `Autoencoder` class\n",
    "In `pytorch`, a neural network model is defined as a class that inherits from `nn.Module`. The class must have an `__init__` method that defines the layers of the network and a `forward` method that defines how input data is passed through the network. The `forward` method should return the output of the network. In this case, the `Autoencoder` class has an encoder and a decoder. Fully connected layers are called `Linear` in `Pytorch`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Autoencoder class\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        \n",
    "        # Encoder: Linear layer with ReLU activation\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(28*28, hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # Decoder: Linear layer with Sigmoid activation\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, 28*28),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encode the input\n",
    "        x = self.encoder(x)\n",
    "        # Decode the latent representation\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I.2.2. Prepare the data loaders\n",
    "Data loaders are used to iterate through data in batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader  = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I.2.3. Instantiate the model\n",
    "We instantiate the model with a hidden dimension of 10. The `.to(device)` method moves the model to the GPU if available\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 10\n",
    "\n",
    "simple_ae = Autoencoder(hidden_dim=hidden_dim).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I.2.4. Define loss and optimizer\n",
    "Common loss functions can be access through pytorch's `.nn` module, whereas common optimizers are found in pytorch's `.optim` module. We have already imported both, as `nn` and `optim` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss() # Mean Squared Error loss\n",
    "optimizer = optim.Adam(simple_ae.parameters(), lr=1e-3) # Adam optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I.2.5. Train the AE\n",
    "Before each gradient descent iteration, it is extremely important to reset the gradients of the weights to 0 using the method `.zero_grad()`, otherwise, the new gradients are accumulated to those of previous iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    simple_ae.train()\n",
    "    running_loss = 0.0\n",
    "    for images in train_loader:\n",
    "        # Move images to device\n",
    "        images = images.to(device)\n",
    "        \n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = simple_ae(images)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = criterion(outputs, images)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * images.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I.2.6. Evaluate the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the results both by computing the test loss and by visualizing the reconstructed images against the original ones, as for PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_ae.eval()\n",
    "test_loss = 0.0\n",
    "with torch.no_grad():\n",
    "    for images in test_loader:\n",
    "        # Move images to the device\n",
    "        images = images.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = simple_ae(images)\n",
    "        loss = criterion(outputs, images)\n",
    "        test_loss += loss.item() * images.size(0)\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print(f\"Test Loss: {test_loss:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a bath from the test loader\n",
    "images = next(iter(test_loader))\n",
    "images = images.to(device)\n",
    "\n",
    "# Get the AE reconstructions of the selected images\n",
    "ae_reconstruction = simple_ae(images)\n",
    "\n",
    "# Reshape the images for plotting\n",
    "random_images = images.cpu().numpy().reshape(-1, 28, 28)\n",
    "ae_reconstruction = ae_reconstruction.cpu().detach().numpy().reshape(-1, 28, 28)\n",
    "\n",
    "# Plot the original images and their PCA reconstructions\n",
    "image_comparison(random_images, ae_reconstruction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Autoencoders vs PCA\n",
    "\n",
    "The objective of this section is to review the following concepts, seen during the lesson:\n",
    "> 1. A linear autoencoder learnt on the reconstruction loss is equivalent to PCA.\n",
    "> 2. An autoencoder with nonlinear activations is more powerful than PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### II.1. Linear AE vs PCA\n",
    "In order to compare linear AEs and PCA, we will perform a benchmarking experiment. We will compare the PCA model with $p$ principal components with an undercomplete autoencoder with $p$ hidden dimensions, for different values of $p$. As a matter of fact, we will be using multiple autoencoder architectures, the hidden dimension will always be $p$, but the width and depth of the autoencoders may vary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### II.1.1. PCA training\n",
    "Write a function that trains PCA with $p$ principal components by completing the `TODO` flag below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_pca(p):\n",
    "    \"\"\"Trains a PCA model with p principal components\n",
    "\n",
    "    Args:\n",
    "        p (int): Number of principal components\n",
    "    \n",
    "    Returns:\n",
    "        PCA: Trained PCA model\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: Complete the function according to the docstring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/pca.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### II.1.2. Linear AE training\n",
    "Write a function to train a linear autoencoder with the given hidden dimensions, width and depth by completing the `TODO` flags below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearAutoencoder(nn.Module):\n",
    "    def __init__(self, hidden_dim, width, depth):\n",
    "        super(LinearAutoencoder, self).__init__()\n",
    "        \n",
    "        # Intialize the encoder and decoder as empty Sequential models\n",
    "        # We will add layers dynamically to these Sequential models according to the depth\n",
    "        encoder = nn.Sequential()\n",
    "        decoder = nn.Sequential()\n",
    "\n",
    "        if depth < 1:\n",
    "            raise ValueError(\"Depth must be at least 1\") # TODO: Raise a ValueError\n",
    "\n",
    "        if depth == 1:\n",
    "            # In this case, we ignore the width parameter\n",
    "            # and add a single linear layer to the encoder and decoder\n",
    "            # with the appropriate dimensions.\n",
    "            encoder.add_module(\"linear_1\", nn.Linear(28*28, hidden_dim))\n",
    "            decoder.add_module(\"linear_1\", nn.Linear(hidden_dim, 28*28))\n",
    "\n",
    "        else:\n",
    "            # TODO: Add the first linear layer to the encoder\n",
    "            for i in range(2, depth):\n",
    "                # TODO: Add intermediate linear layers to the encoder\n",
    "            # TODO: Add the last linear layer to the encoder\n",
    "\n",
    "            # TODO: Add all necessary layers to the decoder\n",
    "\n",
    "        # Assign the encoder and decoder to self so that they are recognized as part of the model\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    # TODO: Implement the forward method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/linear_ae.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_autoencoder(hidden_dim, width, depth, epochs=5):\n",
    "    # Instantiate the LinearAutoencoder model\n",
    "    model = LinearAutoencoder(hidden_dim=hidden_dim, width=width, depth=depth).to(device)\n",
    "\n",
    "    # Define the criterion and optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    \n",
    "    # Train the model\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for images in train_loader:\n",
    "            # Move images to device\n",
    "            images = images.to(device)\n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            # Compute loss\n",
    "            loss = criterion(outputs, images)\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # Update running loss\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "\n",
    "        # Compute and print the epoch loss\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {epoch_loss:.6f}\")\n",
    "\n",
    "    return model, epoch_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### II.1.3. Running the benchmark\n",
    "Complete all the `TODO` flags below and perform the benchmark. Feel free to change the arrays `hidden_dims`, `ae_widths` and `ae_depths`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_benchmark(hidden_dims, ae_widths, ae_depths):\n",
    "    \"\"\"Runs a benchmark on the given hidden dimensions, autoencoder widths, and autoencoder depths\n",
    "\n",
    "    Args:\n",
    "        hidden_dims (list): A list of hidden dimensions / principal components to test\n",
    "        ae_widths (list): A list of autoencoder widths to test\n",
    "        ae_depths (list): A list of autoencoder depths to test\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary containing the PCA training loss\n",
    "        dict: Dictionary containing the PCA test loss\n",
    "        dict: Dictionary containing the autoencoder training loss\n",
    "        dict: Dictionary containing the autoencoder test loss\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize dictionaries to store results\n",
    "    pca_train_loss = {}\n",
    "    pca_test_loss = {}\n",
    "    ae_train_loss = {}\n",
    "    ae_test_loss = {}\n",
    "\n",
    "    # Iterate through the hidden dimensions\n",
    "    for p in hidden_dims:\n",
    "        print(f\"Training PCA model with {p} hidden dims\")\n",
    "\n",
    "        # TODO: Train a PCA model with p hidden dimensions\n",
    "\n",
    "        # TODO: Build reconstruction of train/test data using the PCA model\n",
    "\n",
    "        # Calculate the train / test MSE of the PCA model\n",
    "        mse_train_pca =  # TODO: Evaluate the PCA model on train data\n",
    "        mse_test_pca =  # TODO: Evaluate the PCA model on test data\n",
    "        print(f\"Train MSE: {mse_train_pca}, Test MSE: {mse_test_pca}\")\n",
    "        \n",
    "        # Store the results in the dictionaries\n",
    "        pca_train_loss[p] = mse_train_pca\n",
    "        pca_test_loss[p] = mse_test_pca\n",
    "\n",
    "        # Iterate through the autoencoder widths and depths\n",
    "        for width in ae_widths:\n",
    "            for depth in ae_depths:\n",
    "                print(f\"Training autoencoder with {p} hidden dims, width={width}, depth={depth}\")\n",
    "\n",
    "                # TODO: Initialize and train the autoencoder model\n",
    "\n",
    "                # Build reconstruction of test data using AE and compute test loss\n",
    "                model.eval()\n",
    "                test_loss = 0.0\n",
    "                with torch.no_grad():\n",
    "                    for images in test_loader:\n",
    "                        # TODO: Move images to device\n",
    "                        # TODO: Forward pass on test images\n",
    "                        loss = # TODO: Compute loss\n",
    "                        test_loss += loss.item() * images.size(0)\n",
    "                    \n",
    "                    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "                # Store the results in the dictionaries\n",
    "                ae_train_loss[(p, width, depth)] = # TODO: Store the train loss\n",
    "                ae_test_loss[(p, width, depth)] = # TODO: Store the test loss\n",
    "                print(f\"Train MSE: {mse_train_ae}, Test MSE: {mse_test_ae}\")\n",
    "\n",
    "    return pca_train_loss, pca_test_loss, ae_train_loss, ae_test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/pca_vs_linear_ae_benchmark.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dims = [1, 2, 4, 8, 16]\n",
    "ae_widths = [64] # We will only test one width, otherwise it takes too long...\n",
    "ae_depths = [1, 2, 3]\n",
    "\n",
    "# TODO: Run the benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/run_benchmark.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### II.1.4. Visualize the results\n",
    "Compare the losses of the different models by plotting them into two similar graphs, one for the training MSE and another one for the test MSE:\n",
    "- The $x$-axis should contain the different values $p$ for the hidden dimensions / principal components (in logarithmic scale).\n",
    "- The $y$-axis should contain the corresponding MSE values.\n",
    "- There should be one curve per model, with its own color and label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def plot_losses(pca_train_loss, pca_test_loss, ae_train_loss, ae_test_loss):\n",
    "    \"\"\"Plots the training and test losses for the PCA and autoencoder models.\n",
    "    Produces two side-to-side plots for the train losses on the left \n",
    "    and the test losses on the right.\n",
    "\n",
    "    Args:\n",
    "        pca_train_loss (dict): Dictionary of PCA training losses\n",
    "        pca_test_loss (dict): Dictionary of PCA test losses\n",
    "        ae_train_loss (dict): Dictionary of autoencoder training losses (keys are tuples of (hidden_dim, width, depth))\n",
    "        ae_test_loss (dict): Dictionary of autoencoder test losses (keys are tuples of (hidden_dim, width, depth))\n",
    "    \"\"\"\n",
    "    # Create dictionaries to group the autoencoder losses by width and depth\n",
    "    ae_train_grouped = defaultdict(list)\n",
    "    ae_test_grouped = defaultdict(list)\n",
    "\n",
    "    # Group losses by (width, depth) to have one curve per autoencoder model\n",
    "    for (hidden_dim, width, depth), loss in ae_train_loss.items():\n",
    "        ae_train_grouped[(width, depth)].append((hidden_dim, loss))\n",
    "\n",
    "    for (hidden_dim, width, depth), loss in ae_test_loss.items():\n",
    "        ae_test_grouped[(width, depth)].append((hidden_dim, loss))\n",
    "\n",
    "    # Sort the losses by hidden_dim for each autoencoder model\n",
    "    for key in ae_train_grouped:\n",
    "        ae_train_grouped[key] = sorted(ae_train_grouped[key], key=lambda x: x[0])\n",
    "    for key in ae_test_grouped:\n",
    "        ae_test_grouped[key] = sorted(ae_test_grouped[key], key=lambda x: x[0])\n",
    "\n",
    "    # Create a figure with two subplots, side-by-side\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "    # Plot PCA losses\n",
    "    ax[0].plot(list(pca_train_loss.keys()), list(pca_train_loss.values()), label='PCA Train Loss', marker='o')\n",
    "    ax[1].plot(list(pca_test_loss.keys()), list(pca_test_loss.values()), label='PCA Test Loss', marker='o')\n",
    "\n",
    "    # Plot Autoencoder losses grouped by (width, depth)\n",
    "    for (width, depth), values in ae_train_grouped.items():\n",
    "        hidden_dims = [v[0] for v in values]\n",
    "        losses = [v[1] for v in values]\n",
    "        ax[0].plot(hidden_dims, losses, label=f'AE Train Loss (width={width}, depth={depth})', marker='o')\n",
    "\n",
    "    for (width, depth), values in ae_test_grouped.items():\n",
    "        hidden_dims = [v[0] for v in values]\n",
    "        losses = [v[1] for v in values]\n",
    "        ax[1].plot(hidden_dims, losses, label=f'AE Test Loss (width={width}, depth={depth})', marker='o')\n",
    "\n",
    "    # Set titles and labels\n",
    "    ax[0].set_title('Training Losses')\n",
    "    ax[0].set_xlabel('Hidden Dimension')\n",
    "    ax[0].set_ylabel('Loss')\n",
    "    ax[0].legend()\n",
    "    ax[0].grid(True)\n",
    "\n",
    "    ax[1].set_title('Test Losses')\n",
    "    ax[1].set_xlabel('Hidden Dimension')\n",
    "    ax[1].set_ylabel('Loss')\n",
    "    ax[1].legend()\n",
    "    ax[1].grid(True)\n",
    "\n",
    "    # Adjust layout for better spacing\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_losses(pca_train_loss, pca_test_loss, ae_train_loss, ae_test_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### II.1.5. Conclusion\n",
    "Think about the following questions, do not hesitate to call us (the teaching staff) for a brief discussion about them !\n",
    "- Can we see any difference between a linear AE and PCA?\n",
    "- Does increasing depth/width have an impact on the performance of the linear AE? Why?\n",
    "- For the task of data compression, if you had to choose between PCA with $p$ principal components, or a linear AE with $p$ hidden dimensions, which model would you choose? What are the reasons behind your choice?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.2. Nonlinear AEs vs PCA\n",
    "In this section we will compare some of the non-linear AE models seen during the lesson to our PCA baseline. Indeed, if we are going to adopt an AE model for a given task, we will need to make sure that its performance is better than that of PCA, otherwise there is no point on adopting a more complex architecture.\n",
    "The models we will evaluate are the following ones:\n",
    "> - Undercomplete AE\n",
    "> - Denoising AE\n",
    "\n",
    "To keep it simple, we will omit the implementations of the sparse and contractive autoencoders.\n",
    "Once again, we will perform a benchmarking experiment in order to evaluate the different AE models and compare them agains PCA and against each other.\n",
    "\n",
    "Throughout this section, we will fix: \n",
    "- An array of hidden dimensions to test\n",
    "- The depth of the AE architectures to be defined. \n",
    "- The width of the AE architectures to be defined.\n",
    "- The batch size.\n",
    "- The number of training epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_DIMS = [1, 2, 4, 8, 16]\n",
    "INPUT_DIM = 28*28\n",
    "WIDTH = 128\n",
    "DEPTH = 2\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of the models that we are studying, we will need to:\n",
    "- Define the architecture.\n",
    "- Train the model with different hyper-parameters.\n",
    "- Select the hyper-parameters corresponding to the best model.\n",
    "- Evaluate the model.\n",
    "\n",
    "As it is customary in Deep Learning practice, the hyper-parameter optimization is done with the help of a validation set, therefore, we will split the test dataset into a validation dataset and a proper test dataset, and prepare the corresponding data loaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split test data into validation and test sets\n",
    "val_dataset, test_dataset = torch.utils.data.random_split(test_dataset, [5000, 5000])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice.** In order to perform the benchmark explained above, complete the following sections by addressing all the `TODO` flags in them:\n",
    "1. Define a common architecture for both models.\n",
    "2. Train and evaluate the undercomplete AE. Select the best model after hyper-parameter optimization if applies.\n",
    "3. Train and evaluate the denoising AE. Select the best model after hyper-parameter optimization if applies.\n",
    "7. Compare the performances (MSE loss) of the selected models (after hyper-parameter optimization) between each other and agains PCA.\n",
    "8. Visualize the image reconstructions for both models and for PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### II.2.1. Architecture\n",
    "**Question.** How many different architectures should we define ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define a general autoencoder architecture with the fixed global parameters\n",
    "# all activations are ReLU except the last one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/common_ae_architecture.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### II.2.2. Undercomplete AE\n",
    "**Question.** Are there any hyper-parameters involved in the training loss of an undercomplete AE?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the undercomplete AE for the different hidden dimensions\n",
    "\n",
    "# Store the models, along with the losses\n",
    "ucae_models = {} # For visualization of image reconstructions\n",
    "ucae_train_losses = {}\n",
    "ucae_val_losses = {}\n",
    "ucae_test_losses = {}\n",
    "\n",
    "for p in HIDDEN_DIMS:\n",
    "    print(f\"Training undercomplete AE with {p} hidden dims\")\n",
    "\n",
    "    # TODO: Instantiate the model and move it to the device\n",
    "\n",
    "    # TODO: Set the loss and optimizer\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        # TODO: Set the model to training mode\n",
    "        # TODO: Initialize running training and validation loss for the epoch\n",
    "\n",
    "        # TODO: Training loop\n",
    "    \n",
    "        # Compute average training loss for the epoch\n",
    "        train_loss = # TODO: Compute the average training loss\n",
    "\n",
    "        # Validation loop\n",
    "        undercomplete_ae.eval()  # Set model to evaluation mode\n",
    "        with torch.no_grad():  # Disable gradient calculation for validation\n",
    "            for images in val_loader:\n",
    "                # Move images to device\n",
    "                images = images.to(device)\n",
    "                # Forward pass\n",
    "                outputs = undercomplete_ae(images)\n",
    "                # Compute loss\n",
    "                loss = criterion(outputs, images)\n",
    "                # Accumulate validation loss\n",
    "                running_val_loss += loss.item() * images.size(0)\n",
    "\n",
    "        # Compute average validation loss for the epoch\n",
    "        val_loss = running_val_loss / len(val_loader.dataset)\n",
    "\n",
    "        # Print training and validation statistics for the epoch\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Training Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}')\n",
    "\n",
    "    # Save the trained model and losses\n",
    "    ucae_models[p] = undercomplete_ae\n",
    "    ucae_train_losses[p] = train_loss\n",
    "    ucae_val_losses[p] = val_loss\n",
    "\n",
    "    # TODO: Evaluate the model on the test set\n",
    "    \n",
    "    # Compute average test loss\n",
    "    test_loss = # TODO: Compute the average test loss\n",
    "    ucae_test_losses[p] = test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/train_ucae.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### II.2.3. Denoising AE\n",
    "**Question.** Are there any new hyper-parameters involved in the training of the Denoising AE?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the denoising AE with different noise levels\n",
    "\n",
    "# Set the hyper-parameters\n",
    "noise_levels = [0.003, 0.01, 0.03, 0.1]  # Noise levels to test\n",
    "\n",
    "# Store the models, along with the losses\n",
    "denoising_models = {}\n",
    "denoising_train_losses = {}\n",
    "denoising_val_losses = {}\n",
    "denoising_test_losses = {}\n",
    "\n",
    "for p in HIDDEN_DIMS:\n",
    "    for noise_level in noise_levels:\n",
    "        print(f\"Training denoising AE with {p} hidden dims and noise level {noise_level}\")\n",
    "        # TODO: Instantiate the model and move it to the device\n",
    "\n",
    "        # TODO: Set the loss and optimizer\n",
    "\n",
    "        for epoch in range(EPOCHS):\n",
    "            # TODO: Set the model to training mode\n",
    "            # TODO: Initialize running training and validation loss for the epoch\n",
    "\n",
    "            # TODO: Training loop keeping in mind to:\n",
    "            # generate noisy images with the given noise level\n",
    "            # clip pixel values to [0, 1] after adding noise\n",
    "            # do the forward pass on the noisy images\n",
    "            # compute the loss by comparing the outputs with the ORIGINAL images\n",
    "            \n",
    "            # TODO: Compute average training loss for the epoch\n",
    "\n",
    "            # TODO: Validation loop keeping in mind to:\n",
    "            # follow the same procedure as for the training loop.\n",
    "\n",
    "            # TODO: Compute average validation loss for the epoch\n",
    "\n",
    "            # TODO: Print training and validation statistics for the epoch\n",
    "\n",
    "        # TODO: Save model and losses\n",
    "        denoising_models[(p, noise_level)] = # TODO: Save the model\n",
    "        denoising_train_losses[(p, noise_level)] = # TODO: Save the training loss\n",
    "        denoising_val_losses[(p, noise_level)] = # TODO: Save the validation loss\n",
    "\n",
    "        # TODO: Evaluate the model on the test set\n",
    "        \n",
    "        # TODO: Compute and save the average test loss\n",
    "        test_loss = # TODO: Compute the average test loss\n",
    "        denoising_test_losses[(p, noise_level)] = test_loss\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/train_denoising_ae.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### II.2.4. Loss plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train PCA\n",
    "\n",
    "pca_train_losses = {}\n",
    "pca_val_losses = {}\n",
    "pca_test_losses = {}\n",
    "\n",
    "for p in HIDDEN_DIMS:\n",
    "    print(f\"Training PCA model with {p} hidden dims\")\n",
    "\n",
    "    # Train the PCA model\n",
    "    pca = train_pca(p)\n",
    "\n",
    "    # Evaluate the PCA model on the training and validation data\n",
    "    pca_reconstruction_train = pca.inverse_transform(pca.transform(train_dataset))\n",
    "    pca_reconstruction_val = pca.inverse_transform(pca.transform(val_dataset))\n",
    "    pca_reconstruction_test = pca.inverse_transform(pca.transform(test_dataset))\n",
    "\n",
    "    mse_train_pca = mean_squared_error(train_dataset, pca_reconstruction_train)\n",
    "    mse_val_pca = mean_squared_error(val_dataset, pca_reconstruction_val)\n",
    "    mse_test_pca = mean_squared_error(test_dataset, pca_reconstruction_test)\n",
    "    print(f\"Train MSE: {mse_train_pca}, Validation MSE: {mse_val_pca}\")\n",
    "\n",
    "    pca_train_losses[p] = mse_train_pca\n",
    "    pca_val_losses[p] = mse_val_pca\n",
    "    pca_test_losses[p] = mse_test_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionaries to group the denoising AE losses by noise level\n",
    "denoising_train_grouped = defaultdict(list)\n",
    "denoising_val_grouped = defaultdict(list)\n",
    "\n",
    "# Group losses by noise level to have one curve per denoising model\n",
    "for (hidden_dim, noise_level), loss in denoising_train_losses.items():\n",
    "    denoising_train_grouped[noise_level].append((hidden_dim, loss))\n",
    "for (hidden_dim, noise_level), loss in denoising_val_losses.items():\n",
    "    denoising_val_grouped[noise_level].append((hidden_dim, loss))\n",
    "\n",
    "# Sort the losses by hidden_dim for each denoising model\n",
    "for key in denoising_train_grouped:\n",
    "    denoising_train_grouped[key] = sorted(denoising_train_grouped[key], key=lambda x: x[0])\n",
    "for key in denoising_val_grouped:\n",
    "    denoising_val_grouped[key] = sorted(denoising_val_grouped[key], key=lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure with two subplots, side-by-side\n",
    "# one for training losse curves and the other for validation loss curves\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(14, 4))\n",
    "#fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Plot PCA losses\n",
    "ax[0].plot(list(pca_train_losses.keys()), list(pca_train_losses.values()), label='PCA', marker='o')\n",
    "ax[1].plot(list(pca_val_losses.keys()), list(pca_val_losses.values()), label='PCA', marker='o')\n",
    "#ax[2].plot(list(pca_test_loss.keys()), list(pca_test_loss.values()), label='PCA', marker='o')\n",
    "\n",
    "# Plot undercomplete AE losses\n",
    "ax[0].plot(list(ucae_train_losses.keys()), list(ucae_train_losses.values()), label='UCAE', marker='o')\n",
    "ax[1].plot(list(ucae_val_losses.keys()), list(ucae_val_losses.values()), label='UCAE', marker='o')\n",
    "#ax[2].plot(list(ucae_test_losses.keys()), list(ucae_test_losses.values()), label='UCAE', marker='o')\n",
    "\n",
    "# Plot denoising AE losses\n",
    "for noise_level, values in denoising_train_grouped.items():\n",
    "    hidden_dims = [v[0] for v in values]\n",
    "    losses = [v[1] for v in values]\n",
    "    ax[0].plot(hidden_dims, losses, label=f'Denoising AE (noise={noise_level})', marker='o')\n",
    "\n",
    "for noise_level, values in denoising_val_grouped.items():\n",
    "    hidden_dims = [v[0] for v in values]\n",
    "    losses = [v[1] for v in values]\n",
    "    ax[1].plot(hidden_dims, losses, label=f'Denoising AE (noise={noise_level})', marker='o')\n",
    "\n",
    "# Set titles and labels\n",
    "ax[0].set_title('Training Losses')\n",
    "ax[0].set_xlabel('Hidden Dimension')\n",
    "ax[0].set_ylabel('Loss')\n",
    "ax[0].legend()\n",
    "ax[0].grid(True)\n",
    "\n",
    "ax[1].set_title('Validation Losses')\n",
    "ax[1].set_xlabel('Hidden Dimension')\n",
    "ax[1].set_ylabel('Loss')\n",
    "ax[1].legend()\n",
    "ax[1].grid(True)\n",
    "\n",
    "# Adjust layout for better spacing\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question.** What conclusion do you draw from these plots ? Has anything changes as a consequence of the addition of the non-linear activations ?\n",
    "\n",
    "Since we are using a validation test, we can rely on it for choosing the best noise level in the denoising AE for each choice of the hidden parameter $p$. The code below computes the noise level that achieves best validation loss, and plots a curve of \"best denoising models\" against PCA and the undercomplete autoencoder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the best models on the test set\n",
    "\n",
    "# Dictionary to store the best test losses and their corresponding noise levels\n",
    "best_test_losses = {}\n",
    "\n",
    "# Iterate over hidden dimensions and select the best model based on validation loss\n",
    "for p in HIDDEN_DIMS:\n",
    "    # Find the noise level that has the minimum validation loss for the current hidden dimension\n",
    "    best_noise_level = min(\n",
    "        [noise_level for noise_level in noise_levels],\n",
    "        key=lambda nl: denoising_val_losses[(p, nl)]\n",
    "    )\n",
    "\n",
    "    # Retrieve the best model, train loss, and validation loss for the selected noise level\n",
    "    best_test_loss = denoising_test_losses[(p, best_noise_level)]\n",
    "    best_train_loss = denoising_train_losses[(p, best_noise_level)]\n",
    "    best_val_loss = denoising_val_losses[(p, best_noise_level)]\n",
    "    best_test_losses[p] = best_test_loss\n",
    "\n",
    "    # Print out the best models, their noise levels, and the corresponding losses\n",
    "    print(f\"Best model for hidden dimension {p}:\")\n",
    "    print(f\"Noise level: {best_noise_level}\")\n",
    "    print(f\"Train loss: {best_train_loss}\")\n",
    "    print(f\"Validation loss: {best_val_loss}\")\n",
    "    print(f\"Test loss: {best_test_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot test losses for PCA, UCAE, and best denoising AEs\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(7, 4))\n",
    "\n",
    "# Plot PCA test loss\n",
    "ax.plot(list(pca_test_losses.keys()), list(pca_test_losses.values()), label='PCA', marker='o')\n",
    "\n",
    "# Plot undercomplete AE test loss\n",
    "ax.plot(list(ucae_test_losses.keys()), list(ucae_test_losses.values()), label='UCAE', marker='o')\n",
    "\n",
    "# Plot best denoising AE test loss\n",
    "ax.plot(list(best_test_losses.keys()), list(best_test_losses.values()), label='Best Denoising AE per hidden dim', marker='o')\n",
    "\n",
    "# Set titles and labels\n",
    "ax.set_title('Test Losses')\n",
    "ax.set_xlabel('Hidden Dimension')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.legend()\n",
    "ax.grid(True)\n",
    "\n",
    "# Adjust layout for better spacing\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### II.2.5. Visualization of reconstructions\n",
    "Finally, we are going to compare the reconstructions of the original images by the three models, for the hidden dimension $p=8$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the image reconstructions for \n",
    "# PCA, UCAE, and the best denoising AE model for hidden_dim=8\n",
    "\n",
    "# Get the best denoising AE model for hidden_dim=8\n",
    "denoising_model = denoising_models[(8, 0.03)]\n",
    "\n",
    "# Get a batch of test images\n",
    "images = next(iter(test_loader))\n",
    "images = images.to(device)\n",
    "\n",
    "# Generate noisy images and clip pixel values to [0, 1]\n",
    "noisy_images = images + 0.03 * torch.randn_like(images)\n",
    "noisy_images = torch.clamp(noisy_images, 0, 1)\n",
    "\n",
    "# Reconstruct images using the three models\n",
    "pca_reconstruction = pca.inverse_transform(pca.transform(images.view(images.size(0), -1).cpu().numpy()))\n",
    "ucae_reconstruction = ucae_models[8](images.view(images.size(0), -1)).cpu().detach().numpy()\n",
    "denoising_reconstruction = denoising_model(noisy_images.view(noisy_images.size(0), -1)).cpu().detach().numpy()\n",
    "\n",
    "# Reshape images for plotting to (batch_size, 28, 28)\n",
    "images = images.cpu().numpy().reshape(-1, 28, 28)\n",
    "noisy_images = noisy_images.cpu().numpy().reshape(-1, 28, 28)\n",
    "pca_reconstruction = pca_reconstruction.reshape(-1, 28, 28)\n",
    "ucae_reconstruction = ucae_reconstruction.reshape(-1, 28, 28)\n",
    "denoising_reconstruction = denoising_reconstruction.reshape(-1, 28, 28)\n",
    "\n",
    "\n",
    "# Plot the original, PCA, UCAE, noisy, and denoising AE reconstructed images\n",
    "fig, ax = plt.subplots(5, 6, figsize=(20, 10))\n",
    "\n",
    "for i in range(6):\n",
    "    # Original images\n",
    "    ax[0, i].imshow(images[i], cmap='gray')\n",
    "    ax[0, i].axis('off')\n",
    "    ax[0, 0].set_title('Original')\n",
    "\n",
    "    # PCA reconstructed images\n",
    "    ax[1, i].imshow(pca_reconstruction[i], cmap='gray')\n",
    "    ax[1, i].axis('off')\n",
    "    ax[1, 0].set_title('PCA')\n",
    "\n",
    "    # UCAE reconstructed images\n",
    "    ax[2, i].imshow(ucae_reconstruction[i], cmap='gray')\n",
    "    ax[2, i].axis('off')\n",
    "    ax[2, 0].set_title('UCAE')\n",
    "\n",
    "    # Noisy images\n",
    "    ax[3, i].imshow(noisy_images[i], cmap='gray')\n",
    "    ax[3, i].axis('off')\n",
    "    ax[3, 0].set_title('Noisy')\n",
    "\n",
    "    # Denoising AE reconstructed images\n",
    "    ax[4, i].imshow(denoising_reconstruction[i], cmap='gray')\n",
    "    ax[4, i].axis('off')\n",
    "    ax[4, 0].set_title('Denoising AE')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III.Trasferable Representations?\n",
    "The objective of this section is to answer to the following question:\n",
    "- Are the latent representations learnt by an autoencoder transferable to other tasks ?\n",
    "\n",
    "To that end, we will train an autoencoder on the MNIST dataset, and use the latent representations along with the image labels to train a classifier, and evaluate its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MNIST dataset\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "transform = transforms.ToTensor()\n",
    "batch_size = 64\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset  = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Data loaders\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader  = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and train the model\n",
    "encoding_dim = 10  # Undercomplete dimension\n",
    "autoencoder = Autoencoder(encoding_dim).to(device)\n",
    "\n",
    "criterion = nn.MSELoss()  # Mean Squared Error loss\n",
    "optimizer = optim.Adam(autoencoder.parameters(), lr=1e-3)\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    autoencoder.train()\n",
    "    running_loss = 0.0\n",
    "    for images, _ in train_loader:\n",
    "        # Flatten images\n",
    "        images = images.to(device).view(-1, 28*28)\n",
    "        # Forward pass\n",
    "        outputs = autoencoder(images)\n",
    "        loss = criterion(outputs, images.view(-1, 28*28))\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract latent representations\n",
    "def get_latent_features(model, dataloader):\n",
    "    model.eval()\n",
    "    features = []\n",
    "    labels = []\n",
    "    with torch.no_grad():\n",
    "        for images, lbls in dataloader:\n",
    "            images = images.to(device).view(-1, 28*28)\n",
    "            latent = model.encoder(images)\n",
    "            features.append(latent.cpu())\n",
    "            labels.append(lbls)\n",
    "    features = torch.cat(features)\n",
    "    labels = torch.cat(labels)\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data loaders for classification\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "train_features, train_labels = get_latent_features(autoencoder, train_loader)\n",
    "test_features, test_labels = get_latent_features(autoencoder, test_loader)\n",
    "\n",
    "train_dataset_cls = TensorDataset(train_features, train_labels)\n",
    "test_dataset_cls = TensorDataset(test_features, test_labels)\n",
    "\n",
    "train_loader_cls = DataLoader(dataset=train_dataset_cls, batch_size=batch_size, shuffle=True)\n",
    "test_loader_cls = DataLoader(dataset=test_dataset_cls, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the classifier architecture\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, input_dim=encoding_dim, num_classes=10):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(32, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train the classifier\n",
    "\n",
    "classifier = Classifier().to(device)\n",
    "\n",
    "criterion_cls = nn.CrossEntropyLoss()\n",
    "optimizer_cls = optim.Adam(classifier.parameters(), lr=1e-3)\n",
    "\n",
    "num_epochs_cls = 20\n",
    "\n",
    "for epoch in range(num_epochs_cls):\n",
    "    classifier.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for features, labels in train_loader_cls:\n",
    "        features = features.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # Forward pass\n",
    "        outputs = classifier(features)\n",
    "        loss = criterion_cls(outputs, labels)\n",
    "        # Backward and optimize\n",
    "        optimizer_cls.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer_cls.step()\n",
    "        running_loss += loss.item()\n",
    "        # Calculate accuracy\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    avg_loss = running_loss / len(train_loader_cls)\n",
    "    accuracy = 100 * correct / total\n",
    "\n",
    "    # Compute the test loss and accuracy\n",
    "    classifier.eval()\n",
    "    train_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for features, labels in test_loader_cls:\n",
    "            features = features.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = classifier(features)\n",
    "            loss = criterion_cls(outputs, labels)\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        test_loss = train_loss / len(test_loader_cls)\n",
    "        test_accuracy = 100 * correct / total\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs_cls}], Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%, Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question.** Are the representations learnt by the autoencoder transferable to the classification task ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
